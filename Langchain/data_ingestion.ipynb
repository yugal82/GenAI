{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Loader using langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'speech.txt'}, page_content=\"Cristiano Ronaldo dos Santos Aveiro is a Portuguese professional footballer who plays as a forward for and captains both Saudi Pro League club Al Nassr and the Portugal national team. Widely regarded as one of the greatest players of all time, Ronaldo has won five Ballon d'Or awards, a record three UEFA Men's Player of the Year Awards, and four European Golden Shoes, the most by a European player. He has won 33 trophies in his career, including seven league titles, five UEFA Champions Leagues, the UEFA European Championship and the UEFA Nations League. Ronaldo holds the records for most appearances (183), goals (140) and assists (42) in the Champions League, most appearances (30), assists (8), goals in the European Championship (14), international goals (130) and international appearances (212). He is one of the few players to have made over 1,200 professional career appearances, the most by an outfield player, and has scored over 890 official senior career goals for club and country, making him the top goalscorer of all time.\\n\\nRonaldo began his senior career with Sporting CP, before signing with Manchester United in 2003, winning the FA Cup in his first season. He would also go on to win three consecutive Premier League titles, the Champions League and the FIFA Club World Cup; at age 23, he won his first Ballon d'Or. Ronaldo was the subject of the then-most expensive association football transfer when he signed for Real Madrid in 2009 in a transfer worth â‚¬94 million (Â£80 million). He became a key contributor and formed an attacking trio with Karim Benzema and Gareth Bale which was integral to the team winning four Champions Leagues from 2014 to 2018, including La DÃ©cima. During this period, he won back-to-back Ballons d'Or in 2013 and 2014, and again in 2016 and 2017, and was runner-up three times behind Lionel Messi, his perceived career rival. He also became the club's all-time top goalscorer and the all-time top scorer in the Champions League, and finished as the competition's top scorer for six consecutive seasons between 2012 and 2018. With Real, Ronaldo won four Champions Leagues, two La Liga titles, two Copas del Rey, two UEFA Super Cups and three Club World Cups. In 2018, he signed for Juventus in a transfer worth an initial â‚¬100 million (Â£88 million), the most expensive transfer for an Italian club and for a player over 30 years old. He won two Serie A titles, two Supercoppa Italiana trophies and a Coppa Italia, became the inaugural Serie A Most Valuable Player and became the first footballer to finish as top scorer in the English, Spanish and Italian leagues. He returned to Manchester United in 2021, finishing his only full season as the club's top scorer, before his contract was terminated in 2022. In 2023, he signed for Al Nassr.\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Loader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader('speech.txt')\n",
    "text_doc = loader.load()\n",
    "text_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'AutoImplant2020.pdf', 'page': 0}, page_content='See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/346630651\\nDeep Learning Using Augmentation via Registration: 1st Place Solution to the\\nAutoImplant 2020 Challenge\\nConf erence Paper  · Dec ember 2020\\nDOI: 10.1007/978-3-030-64327-0_6\\nCITATIONS\\n20READS\\n385\\n2 author s:\\nSome o f the author s of this public ation ar e also w orking on these r elat ed pr ojects:\\nAutomatic Cr anial Implant Design  View pr oject\\nDavid Ellis\\nUniv ersity of Nebr aska Medic al Cent er\\n15 PUBLICA TIONS \\xa0\\xa0\\xa095 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nMichele R Aiz enber g\\nUniv ersity of Nebr aska Medic al Cent er\\n47 PUBLICA TIONS \\xa0\\xa0\\xa0307 CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll c ontent f ollo wing this p age was uplo aded b y David Ellis  on 04 Dec ember 2020.\\nThe user has r equest ed enhanc ement of the do wnlo aded file.'),\n",
       " Document(metadata={'source': 'AutoImplant2020.pdf', 'page': 1}, page_content='Deep Learning Using Augmentation via\\nRegistration: 1st Place Solution to the\\nAutoImplant 2020 Challenge\\nDavid G. Ellis[0000−0002−3718−6836]and Michele R.\\nAizenberg[0000−0001−6689−8907]\\nDept. of Neurosurgery, University of Nebraska Medical Center, Omaha, NE, USA\\ndavid.ellis@unmc.edu\\nAbstract. Automatic cranial implant design can save clinicians time\\nand resources by computing the implant shape and size from a single\\nimage of a defective skull. We aimed to improve upon previously pro-\\nposed deep learning methods by augmenting the training data set using\\ntransformations that warped the images into diﬀerent shapes and orien-\\ntations. The transformations were computed by non-linearly registering\\nthe complete skull images between the 100 subjects in the training data\\nset. The transformations were then applied to warp each of the defective\\nand complete skull images so that the shape and orientation resembled\\nthat of a diﬀerent subject in the training set. One hundred ninety-seven\\nof the registrations failed, resulting in an augmented training set of 9,803\\ndefective and complete skull image pairs. The augmented training set was\\nused to train an ensemble of four U-Net models to predict the complete\\nskull shape from the defective skulls using cross-validation. The ensemble\\nof models performed very well and predicted the implant shapes with a\\nmean dice similarity coeﬃcient of 0.942 and a mean Hausdorﬀ distance of\\n3.598mm for all 110 test cases. Our solution ranked ﬁrst among all par-\\nticipants of the AutoImplant 2020 challenge. The code for this project is\\navailable at https://github.com/ellisdg/3DUnetCNN.\\nKeywords: Deep learning ·Shape completion ·Augmentation.\\n1 Introduction\\nAutomatic cranial implant design can save clinicians time and resources by com-\\nputing the implant shape and size needed by a speciﬁc patient based on computed\\ntomography imaging of their head [5, 11, 6, 8]. The AutoImplant 2020 Cranial Im-\\nplant Design Challenge seeks to test varying methods for designing an implant\\nbased on an image of a skull with a defect such that part of the skull is missing\\n[7]. The challenge organizers submitted a baseline solution for this challenge in\\nwhich they experimented with two deep learning solutions [10]. The ﬁrst solution\\nwas to use a cascade style set of models where one model predicts the implant’s\\nshape at low-resolution, and another model subsequently reﬁnes that shape at'),\n",
       " Document(metadata={'source': 'AutoImplant2020.pdf', 'page': 2}, page_content='2 Ellis et al.\\nhigh-resolution. This cascade style solution has the advantage of limiting mem-\\nory use by only computing the high-resolution implant shape on a cropped image\\nrather than the whole image of the skull. However, the authors noted that over-\\nﬁtting to the training set caused the model to have two key limitations in its\\nability to generalize to cases outside of the training set [10]. The ﬁrst limitation\\nwas that the model tended to predict the same implant shape for a given skull,\\neven when the location of the defect had been changed. The second limitation\\nwas that the model was not able to accurately predict implants for defects that\\nwere in diﬀerent locations and diﬀerently shaped than the defects in the training\\nset images. The authors also experimented with using a deep learning network\\ntrained to predict the shape of the skull without defects and gave illustrations\\nof how the model appeared to generalize well to cases outside the training set\\n[10].\\nInspired by these results, we aimed to implement a deep learning solution\\nthat would perform skull completion while learning from a heavily augmented\\ntraining set. Augmentation is a common approach to expand the size of a training\\nset of data so that a model training on the data will avoid overﬁtting and will\\ngeneralize well to cases outside of the training set. Research by Zhao et al.\\nhas previously shown that registrations, along with other transformations, can\\nbe highly eﬀective at augmenting small training sets of medical images [13].\\nZhao et al. showed that the models trained on these augmented training sets\\nperformed much better than the models trained without such augmentations\\n[13]. Therefore, we hypothesized that training models on a data set augmented\\nusing registrations would produce models that are highly accurate at predicting\\nimplant shapes from defective skull images.\\n2 Methods\\n2.1 Data\\nAll data was provided by the organizers of the 2020 AutoImplant challenge. A\\ntraining set was provided with images for 100 subjects along with a test set\\nwith images for 110 subjects. The training set consisted of binary images of the\\ncomplete skull, the defective skull, and the implant for each subject. Renderings\\nof these images are shown in Figure 1 for an illustrative subject. The testing set\\nconsisted of only the defective skulls. One hundred of the testing set subjects\\nhad defects similar in location and shape to the training set, while 10 of the\\ntesting set subjects had defects with shapes and locations that varied from the\\ndefects of the training set.\\n2.2 Augmentation\\nRegistration To augment the training set of images, automatic registrations\\nwere computed between the skull images for each pair of subjects. This aug-\\nmentation increases the size of the training set and allows for similarly shaped'),\n",
       " Document(metadata={'source': 'AutoImplant2020.pdf', 'page': 3}, page_content='Augmentation via Registration 3\\nSkull Defective Skull Implant\\nFig. 1. Three-dimensional mesh renderings of the skull, defective skull, and implant\\nimages for a single subject from the training set.\\nskulls to have varying defect locations. With a training set of 100 images, each\\nindividual image can be registered with and warped into the space of 99 other\\nimages. Therefore, we attempted to warp the images via registrations and create\\n9,900 additional training images. Combined with the original training images,\\nthis would make an augmented training set of 10,000 images.\\nThe “antsRegistrationSyNQuick.sh” script from the Advanced Normaliza-\\ntion Tools (ANTs) package was utilized to compute the combined rigid, aﬃne,\\nand non-linear symmetric image normalization (SyN) warping transformations\\nbetween skull images [3, 2]. For each pair of subjects, the skull of the ﬁrst subject\\nwould be used as the moving image, and the skull of the second subject would be\\nused as the ﬁxed image. The script then computed the transformations to warp\\nthe moving image into the ﬁxed image space. The transformations were then\\napplied to the complete and defective skull images to warp the moving images\\ninto the ﬁxed image space, and the inverse transforms were used to warp the\\nﬁxed images into the moving image space. This was repeated for every pair of\\nsubjects in the training data set.\\nPermutation In order to enhance the model’s ability to predict complete skulls\\nfor various defect locations, the images were mirrored along the anteroposterior\\nand horizontal directions with a 50% probability for each training iteration.\\nScaling In order to make the model robust to variations in image scaling, the\\ntraining images were randomly zoomed in and out with a 75% probability for\\neach training iteration.\\nTranslation In order to make the model robust to variations in the position of\\nthe skull within the image, the training images were randomly translated with\\na 75% probability for each training iteration.'),\n",
       " Document(metadata={'source': 'AutoImplant2020.pdf', 'page': 4}, page_content='4 Ellis et al.\\n2.3 Preprocessing\\nAll of the images were cropped to remove extra background padding in the im-\\nages so that only one voxel of background padding around the non-background\\narea remained [1]. In order that all of the data had the same orientation prior to\\nbeing input into the model, the orientation of the images was set to Right, Ante-\\nrior, Superior (RAS) [1, 4]. After augmentation, the images were resampled down\\nto a size of 176x224x144 voxels. Apart from the registrations, all preprocessing\\nand augmentation steps were performed at run time.\\n2.4 Model\\nWe used a U-Net-style convolutional neural network model with residual con-\\nnections, as shown in Figure 2 [9, 12]. Inspired by the research of Myronenko\\n32\\n64 32\\n128 64\\n256 128\\n512 256 512512 256128 25664 12832\\ncccc1 64 1\\n1x1x1 convIdentity4D tensor\\n3x3x3 strided convolution1x1x1 convolution\\n+ upsamplingResidual block\\ncConcatenation\\nGroup normalization + \\nRELU + 3x3x3 convolution\\n+Summation+Residual block\\nFig. 2. U-Net model architecture. The number of channels at each step is shown in\\nblack.\\nshowing that a large receptive ﬁeld and shallow decoder performed well in the\\nautomatic segmentation for brain tumors [12], our model used a large receptive\\nﬁeld of 176x224x144 voxels. Comparatively, the baseline approach used a recep-\\ntive ﬁeld of 128x128x128 voxels [10]. The encoder to the model consisted of ﬁve\\nlayers, two ResNet style blocks per layer, a base width of 32 channels, dropout,\\nand group normalization. The outputs of each encoding layer were downsampled\\nusing a strided convolution before being input into the next layer. The number of\\nchannels was doubled at each consecutive layer. Each decoding layer consisted of\\na single ResNet style block and took as input the output of the previous decoding\\nlayer concatenated with the output of the encoding layer at the same resolution.\\nA 1x1x1 convolution and sigmoid activation were applied to the output of the\\nﬁnal decoding layer.'),\n",
       " Document(metadata={'source': 'AutoImplant2020.pdf', 'page': 5}, page_content='Augmentation via Registration 5\\n2.5 Training\\nAn ensemble of four models was trained to predict the complete skulls from the\\ndefective skulls of the augmented training set using four-fold cross-validation.\\nEach model was trained using two NVIDIA V100 GPUs with 32 gigabytes of\\nmemory each. Due to limits on computing resources, training was stopped after\\nseven days.\\n2.6 Testing\\nAll four models were used to predict the complete skull for all 110 defective skulls\\nfrom the test set, and the results were averaged across all four models. In order to\\nderive the implant shape from the predicted skull shape, the defective skull was\\nsubtracted from the predicted skull. The diﬀerence image was then thresholded\\nat 0.5. In order to remove spurious voxels from the predicted implant image, one\\niteration of morphological opening was performed, and all voxels not connected\\nto the largest connected component were automatically removed.\\n3 Results\\nOne hundred ninety-seven of the registrations failed, resulting in an augmented\\ntraining set of 9803 sets of complete and defective skull images. Figure 3 shows\\nan example of augmentations via registrations between two illustrative subjects.\\nThe evaluation of the Dice similarity coeﬃcients (DSC) and Hausdorﬀ dis-\\ntances (HD) was computed by the organizers and reported in Table 1 and Figure\\n4. The results are shown for the 100 test cases with defects resembling that of\\nthe training cases as well as the 10 test cases with defect shapes and locations\\nthat varied from the training set. Qualitatively, the predicted implants matched\\nTable 1. Mean Dice similarity coeﬃcient (DSC) and Hausdorﬀ distances (HD) for the\\n100 test cases with defects resembling the training set as well as for the 10 test cases\\nwith defects that varied from the training set in shape and location.\\nTest 100 Test 10 Overall\\nBaseline\\n[10]DSC 0.856 - -\\nHD (mm) 5.183 - -\\nOursDSC 0.944 0.932 0.942\\nHD (mm) 3.564 3.934 3.598\\nthe shape of the holes in the defective skulls well regardless of defect shape and\\nlocation, as shown in Figure 5.'),\n",
       " Document(metadata={'source': 'AutoImplant2020.pdf', 'page': 6}, page_content='6 Ellis et al.\\nSubject ASubject B\\nSubject BWarpedSubject AWarpedWarping via Registration\\nFig. 3. Example of augmentations produced via registration. The non-linear registra-\\ntion is computed between the skull images of Subject A and Subject B. Then, the\\ndefective skull, shown in gray, as well as the implant, shown in red, are warped and\\ntranslated using the computed non-linear registration. This produces two additional\\nsets of defective skull and implant pairs from every pair of subjects in the training set.\\nTest 100 Test 100.8000.8250.8500.8750.9000.9250.9500.9751.000Dice Similarity Coefficient\\n(higher is better)\\nTest 100 Test 10246810Hausdorff Distance (mm)\\n(lower is better)baseline\\nFig. 4. Distribution of the Dice similarity coeﬃcient and the Hausdorﬀ distances for\\nthe 100 test cases and the 10 test cases with defects that varied from the training set\\nin shape and location. For comparison, the average scores for the baseline method on\\nthe 100 test cases are shown as the dashed gray line [10].'),\n",
       " Document(metadata={'source': 'AutoImplant2020.pdf', 'page': 7}, page_content='Augmentation via Registration 7\\nFig. 5. Examples of defective skulls (gray) and the predicted implants (red) from cases\\nin the 100-case test set (top row) and the 10-case test set (bottom row). The predicted\\nimplants ﬁll the defects in the skulls well regardless of defect shape and location.'),\n",
       " Document(metadata={'source': 'AutoImplant2020.pdf', 'page': 8}, page_content='8 Ellis et al.\\n4 Discussion\\nThe evaluation metrics for our approach were much better than those reported\\nusing the baseline approach without augmentation [10]. For reference, the mean\\nDSC and HD for the baseline approach on the 100 test cases was 0.855 and\\n5.44mm [10], respectively, while our approach resulted in DSC and HD mea-\\nsures of 0.944 and 3.564mm, respectively. This improvement in evaluation met-\\nrics likely resulted from a number of improvements we made over the baseline\\napproach. The most prominent improvement was the automatic augmentation\\nof the training data via registration. This augmentation prevents overﬁtting by\\nallowing similarly shaped skulls to have varying defect locations. By using regis-\\ntrations, we were able to increase the size of the training set from 100 image pairs\\nto 9803 image pairs. While manually creating a training set of this size would\\nrequire an incredible amount of time, using registrations allows for the augmenta-\\ntions to be computed automatically without manual intervention. Furthermore,\\nthe permuting, scaling, and translating augmentations performed during train-\\ning may have also improved performance by keeping the models from overﬁtting\\nto the training set.\\nThe DSC and HD scores were only slightly worse for the test set of 10 sub-\\njects with unique defects, as shown in Table 1 and Figure 4, despite the models\\nnot being trained on cases with similar defects. The ability of the models to\\ngeneralize to these cases is likely the result of using a shape completion strategy\\nalong with permutation augmentations. The shape completion approach forced\\nthe model to focus on generating a complete skull, regardless of the defect shape.\\nThe permutation augmentations allowed the model to train on defects that were\\nﬂipped in orientation from the locations in the training set. Though these aug-\\nmentation strategies performed very well, further improvement would likely be\\nseen by adding skulls to the training set of images that have more variation in\\ndefect shape and location.\\nTo remove spurious voxels from the implant predictions, we used a morpho-\\nlogical opening procedure that removed voxels that were only partially or weakly\\nconnected to the predicted implant. This was eﬀective but likely also resulted\\nin a loss of edge voxels at the corners of the implant that should have been\\nincluded in the prediction. Future work could focus on ﬁnding a more optimal\\nway to remove these spurious predictions while retaining the correctly predicted\\ncorner voxels. One approach may be to experiment with threshold levels.\\n5 Conclusion\\nWe demonstrated that registrations between anatomical CT images could eﬀec-\\ntively augment a training set of images for skull shape completion. The model\\ntrained on the augmented data set was able to accurately predict complete skull\\nshapes much better than the baseline approach that was trained without using\\nsuch augmentations.'),\n",
       " Document(metadata={'source': 'AutoImplant2020.pdf', 'page': 9}, page_content='Augmentation via Registration 9\\n6 Acknowledgments\\nThis work was completed utilizing the Holland Computing Center of the Univer-\\nsity of Nebraska, which receives support from the Nebraska Research Initiative.\\nReferences\\n1. Abraham, A., Pedregosa, F., Eickenberg, M., Gervais, P., Mueller,\\nA., Kossaiﬁ, J., Gramfort, A., Thirion, B., Varoquaux, G.: Ma-\\nchine learning for neuroimaging with scikit-learn. Frontiers in Neu-\\nroinformatics 8, 14 (2014). https://doi.org/10.3389/fninf.2014.00014,\\nhttps://www.frontiersin.org/article/10.3389/fninf.2014.00014\\n2. Avants, B.B., Epstein, C.L., Grossman, M., Gee, J.C.: Symmetric diﬀeomorphic\\nimage registration with cross-correlation: evaluating automated labeling of elderly\\nand neurodegenerative brain. Medical image analysis 12(1), 26–41 (2008)\\n3. Avants, B.B., Tustison, N., Song, G.: Advanced normalization tools (ants). Insight\\nj2(365), 1–35 (2009)\\n4. Brett, M., Markiewicz, C.J., Hanke, M., Cˆ ot´ e, M.A., Cipollini, B., McCarthy,\\nP., Jarecka, D., Cheng, C.P., Halchenko, Y.O., Cottaar, M., Ghosh, S., Lar-\\nson, E., Wassermann, D., Gerhard, S., Lee, G.R., Wang, H.T., Kastman, E.,\\nKaczmarzyk, J., Guidotti, R., Duek, O., Rokem, A., Madison, C., Morency,\\nF.C., Moloney, B., Goncalves, M., Markello, R., Riddell, C., Burns, C., Mill-\\nman, J., Gramfort, A., Lepp¨ akangas, J., S´ olon, A., van den Bosch, J.J., Vin-\\ncent, R.D., Braun, H., Subramaniam, K., Gorgolewski, K.J., Raamana, P.R.,\\nNichols, B.N., Baker, E.M., Hayashi, S., Pinsard, B., Haselgrove, C., Hymers,\\nM., Esteban, O., Koudoro, S., Oosterhof, N.N., Amirbekian, B., Nimmo-Smith,\\nI., Nguyen, L., Reddigari, S., St-Jean, S., Panﬁlov, E., Garyfallidis, E., Varo-\\nquaux, G., Legarreta, J.H., Hahn, K.S., Hinds, O.P., Fauber, B., Poline, J.B.,\\nStutters, J., Jordan, K., Cieslak, M., Moreno, M.E., Haenel, V., Schwartz, Y.,\\nBaratz, Z., Darwin, B.C., Thirion, B., Papadopoulos Orfanos, D., P´ erez-Garc´ ıa,\\nF., Solovey, I., Gonzalez, I., Palasubramaniam, J., Lecher, J., Leinweber, K., Rakti-\\nvan, K., Fischer, P., Gervais, P., Gadde, S., Ballinger, T., Roos, T., Reddam, V.R.,\\nfreec84: nipy/nibabel: 3.1.1 (Jun 2020). https://doi.org/10.5281/zenodo.3924343,\\nhttps://doi.org/10.5281/zenodo.3924343\\n5. Chen, X., Xu, L., Li, X., Egger, J.: Computer-aided implant design for the restora-\\ntion of cranial defects. Scientiﬁc reports 7(1), 1–10 (2017)\\n6. Egger, J., Gall, M., Tax, A., ¨Ucal, M., Zeﬀerer, U., Li, X., von Campe, G., Sch¨ afer,\\nU., Schmalstieg, D., Chen, X.: Interactive reconstructions of cranial 3d implants\\nunder mevislab as an alternative to commercial planning software. PLoS One 12(3),\\ne0172694 (2017)\\n7. Egger, J., Li, J., Chen, X., Sch¨ afer, U., of Campe, G., Krall, M., Zeﬀerer, U.,\\nGsaxner, C., Pepe, A., Schmalstieg, D.: Towards the Automatization of Cranial Im-\\nplant Design in Cranioplasty (Mar 2020). https://doi.org/10.5281/zenodo.3715953,\\nhttps://doi.org/10.5281/zenodo.3715953\\n8. Fuessinger, M.A., Schwarz, S., Cornelius, C.P., Metzger, M.C., Ellis, E., Probst, F.,\\nSemper-Hogg, W., Gass, M., Schlager, S.: Planning of skull reconstruction based on\\na statistical shape model combined with geometric morphometrics. International\\njournal of computer assisted radiology and surgery 13(4), 519–529 (2018)'),\n",
       " Document(metadata={'source': 'AutoImplant2020.pdf', 'page': 10}, page_content='10 Ellis et al.\\n9. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In:\\nProceedings of the IEEE conference on computer vision and pattern recognition.\\npp. 770–778 (2016)\\n10. Li, J., Pepe, A., Gsaxner, C., von Campe, G., Egger, J.: A baseline approach\\nfor autoimplant: the miccai 2020 cranial implant design challenge. arXiv preprint\\narXiv:2006.12449 (2020)\\n11. Morais, A., Egger, J., Alves, V.: Automated computer-aided design of cranial im-\\nplants using a deep volumetric convolutional denoising autoencoder. In: Rocha, ´A.,\\nAdeli, H., Reis, L.P., Costanzo, S. (eds.) New Knowledge in Information Systems\\nand Technologies. pp. 151–160. Springer International Publishing, Cham (2019)\\n12. Myronenko, A.: 3d mri brain tumor segmentation using autoencoder regularization.\\nIn: International MICCAI Brainlesion Workshop. pp. 311–320. Springer (2018)\\n13. Zhao, A., Balakrishnan, G., Durand, F., Guttag, J.V., Dalca, A.V.: Data augmen-\\ntation using learned transformations for one-shot medical image segmentation. In:\\nProceedings of the IEEE conference on computer vision and pattern recognition.\\npp. 8543–8553 (2019)\\nView publication stats')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pdf document loader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "pdf_loader = PyPDFLoader('AutoImplant2020.pdf')\n",
    "pdf_doc = pdf_loader.load()\n",
    "pdf_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.realmadrid.com/en-US/the-club/history/football-legends/cristiano-ronaldo-dos-santos-aveiro'}, page_content='Full nameCristiano Ronaldo Dos Santos AveiroPlace of birthFunchal (Portugal)Date of birth05/02/1985Real Madrid\\'s all-time leading goalscorerPosition: ForwardCompetitive appearances: 438Goals: 451International caps with Portugal: 154Cristiano Ronaldo is a part of Real Madrid\\'s legacy and will forever be remember as one of the great icons throughout the club\\'s history. He was unveiled at the Santiago Bernabéu on 6 July 2009, where he was joined by Eusebio and Alfredo Di Stéfano, and since that day, the goals just kept coming. He netted 451 times in 438 competitive appearances with Real Madrid (averaging over a goal a game). He registered in all of the competitions he featured in: 312 in LaLiga, 105 in the Champions League, 22 in the Copa del Rey, six in the Club World Cup, four in the Spanish Super Cup and two in the UEFA Super Cup.Nobody throughout the club\\'s history has scored as many goals as the Portuguese attacker, who boasts an impressive trophy haul as a Real Madrid player: four Champions League crowns, three Club World Cups and UEFA Super Cups apiece, two LaLiga titles, a pair of Copas del Rey and two Spanish Super Cups. This list of honours is completed with four Ballons d\\'Or, three Golden Shoe awards, two The Best awards, whilst he was named UEFA Best Player in Europe three times and landed the Pichichi crown on three occasions.A spell full of recordsDuring the course of his nine seasons as a Real Madrid player, Ronaldo secured a number of impressive records: the club\\'s all-time leading goalscorer, the leading marksmen in European Cup history (he scored 105 goals for Real Madrid in the Champions League); the all-time leading madridista goalscorer in LaLiga (312); highest number of games in which a player has scored three or more times in LaLiga history (34); and the most goals to have been scored by a Real Madrid player in a single season (61).During his time at the club, he also clinched the record for the most goals scored in a Champions League campaign (17) and ended the competition as the leading goalscorer on six occasions. Club president Florentino Pérez labelled him as \"the heir to Alfredo Di Stéfano”, and just like Don Alfredo, he has left an indelible mark on the history of the best club in the world. Honours With Real Madrid:4 European Cups3 Club World Cups3 UEFA Super Cups2 LaLiga titles2 Copas del Rey2 Spanish Super CupsWith Portugal:1 European Championship with Portugal')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# web based loader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "web_loader = WebBaseLoader(web_path='https://www.realmadrid.com/en-US/the-club/history/football-legends/cristiano-ronaldo-dos-santos-aveiro', bs_kwargs=dict(parse_only=bs4.SoupStrainer(class_=(\"rm-web-legend-detail__body ng-star-inserted\"))))\n",
    "# bs_kwargs is used to only load content which we need. The class_ parameter takes the class names of the html tag that we need to load in the document loader.\n",
    "web_doc = web_loader.load()\n",
    "web_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
